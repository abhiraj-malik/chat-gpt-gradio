{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35184f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Using cached openai-0.27.8-py3-none-any.whl (73 kB)\n",
      "Collecting requests>=2.20\n",
      "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Collecting aiohttp\n",
      "  Using cached aiohttp-3.8.4-cp311-cp311-win_amd64.whl (317 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.2.0-cp311-cp311-win_amd64.whl (96 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\llm\\chatgpt3\\ss\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Using cached urllib3-2.0.3-py3-none-any.whl (123 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2023.5.7-py3-none-any.whl (156 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\llm\\chatgpt3\\ss\\lib\\site-packages (from aiohttp->openai) (23.1.0)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.0.4-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.9.2-cp311-cp311-win_amd64.whl (60 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.3.3-cp311-cp311-win_amd64.whl (32 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: colorama in e:\\llm\\chatgpt3\\ss\\lib\\site-packages (from tqdm->openai) (0.4.6)\n",
      "Installing collected packages: urllib3, tqdm, multidict, frozenlist, charset-normalizer, certifi, async-timeout, yarl, requests, aiosignal, aiohttp, openai\n",
      "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 certifi-2023.5.7 charset-normalizer-3.2.0 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.8 requests-2.31.0 tqdm-4.65.0 urllib3-2.0.3 yarl-1.9.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install openai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21162310",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c8fc822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload your apikey here\n",
    "openai.api_key = open(\"key.txt\", \"r\").read().strip(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e13eed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bf7dcda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Using cached gradio-3.36.1-py3-none-any.whl (19.8 MB)\n",
      "Collecting aiofiles\n",
      "  Using cached aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: aiohttp in e:\\llm\\chatgpt3\\ss\\lib\\site-packages (from gradio) (3.8.4)\n",
      "Collecting altair>=4.2.0\n",
      "  Using cached altair-5.0.1-py3-none-any.whl (471 kB)\n",
      "Collecting fastapi\n",
      "  Using cached fastapi-0.100.0-py3-none-any.whl (65 kB)\n",
      "Collecting ffmpy\n",
      "  Using cached ffmpy-0.3.0-py3-none-any.whl\n",
      "Collecting gradio-client>=0.2.7\n",
      "  Downloading gradio_client-0.2.8-py3-none-any.whl (288 kB)\n",
      "     ------------------------------------ 288.8/288.8 kB 742.9 kB/s eta 0:00:00\n",
      "Collecting httpx\n",
      "  Using cached httpx-0.24.1-py3-none-any.whl (75 kB)\n",
      "Collecting huggingface-hub>=0.14.0\n",
      "  Using cached huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "Requirement already satisfied: jinja2 in e:\\llm\\chatgpt3\\ss\\lib\\site-packages (from gradio) (3.1.2)\n",
      "Collecting markdown-it-py[linkify]>=2.0.0\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Requirement already satisfied: markupsafe in e:\\llm\\chatgpt3\\ss\\lib\\site-packages (from gradio) (2.1.3)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.7.2-cp311-cp311-win_amd64.whl (7.5 MB)\n",
      "Collecting mdit-py-plugins<=0.3.3\n",
      "  Using cached mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.25.1-cp311-cp311-win_amd64.whl (15.0 MB)\n",
      "Collecting orjson\n",
      "  Using cached orjson-3.9.2-cp311-none-win_amd64.whl (195 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.0.3-cp311-cp311-win_amd64.whl (10.6 MB)\n",
      "Collecting pillow\n",
      "  Using cached Pillow-10.0.0-cp311-cp311-win_amd64.whl (2.5 MB)\n",
      "Collecting pydantic\n",
      "  Using cached pydantic-2.0.2-py3-none-any.whl (359 kB)\n",
      "Collecting pydub\n",
      "  Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: pygments>=2.12.0 in e:\\llm\\chatgpt3\\ss\\lib\\site-packages (from gradio) (2.15.1)\n",
      "Collecting python-multipart\n",
      "  Using cached python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
      "Requirement already satisfied: pyyaml in e:\\llm\\chatgpt3\\ss\\lib\\site-packages (from gradio) (6.0)\n",
      "Requirement already satisfied: requests in e:\\llm\\chatgpt3\\ss\\lib\\site-packages (from gradio) (2.31.0)\n",
      "Collecting semantic-version\n",
      "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting uvicorn>=0.14.0\n",
      "  Using cached uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
      "Collecting websockets>=10.0\n",
      "  Using cached websockets-11.0.3-cp311-cp311-win_amd64.whl (124 kB)\n",
      "Requirement already satisfied: jsonschema>=3.0 in e:\\llm\\chatgpt3\\ss\\lib\\site-packages (from altair>=4.2.0->gradio) (4.18.0)\n",
      "Collecting toolz\n",
      "  Using cached toolz-0.12.0-py3-none-any.whl (55 kB)\n",
      "Collecting fsspec\n",
      "  Using cached fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
      "Requirement already satisfied: packaging in e:\\llm\\chatgpt3\\ss\\lib\\site-packages (from gradio-client>=0.2.7->gradio) (23.1)\n",
      "Collecting typing-extensions\n",
      "  Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.12.2-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in e:\\llm\\chatgpt3\\ss\\lib\\site-packages (from huggingface-hub>=0.14.0->gradio) (4.65.0)\n",
      "Collecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Collecting linkify-it-py<3,>=1\n",
      "  Using cached linkify_it_py-2.0.2-py3-none-any.whl (19 kB)\n",
      "Collecting mdit-py-plugins<=0.3.3\n",
      "  Using cached mdit_py_plugins-0.3.2-py3-none-any.whl (50 kB)\n",
      "  Using cached mdit_py_plugins-0.3.1-py3-none-any.whl (46 kB)\n",
      "  Using cached mdit_py_plugins-0.3.0-py3-none-any.whl (43 kB)\n",
      "  Using cached mdit_py_plugins-0.2.8-py3-none-any.whl (41 kB)\n",
      "  Using cached mdit_py_plugins-0.2.7-py3-none-any.whl (41 kB)\n",
      "  Using cached mdit_py_plugins-0.2.6-py3-none-any.whl (39 kB)\n",
      "  Using cached mdit_py_plugins-0.2.5-py3-none-any.whl (39 kB)\n",
      "  Using cached mdit_py_plugins-0.2.4-py3-none-any.whl (39 kB)\n",
      "  Using cached mdit_py_plugins-0.2.3-py3-none-any.whl (39 kB)\n",
      "  Using cached mdit_py_plugins-0.2.2-py3-none-any.whl (39 kB)\n",
      "  Using cached mdit_py_plugins-0.2.1-py3-none-any.whl (38 kB)\n",
      "  Using cached mdit_py_plugins-0.2.0-py3-none-any.whl (38 kB)\n",
      "  Using cached mdit_py_plugins-0.1.0-py3-none-any.whl (37 kB)\n",
      "INFO: pip is looking at multiple versions of markdown-it-py[linkify] to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting markdown-it-py[linkify]>=2.0.0\n",
      "  Using cached markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\llm\\chatgpt3\\ss\\lib\\site-packages (from pandas->gradio) (2.8.2)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
      "Collecting tzdata>=2022.1\n",
      "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "Collecting click>=7.0\n",
      "  Using cached click-8.1.4-py3-none-any.whl (98 kB)\n",
      "Collecting h11>=0.8\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\llm\\chatgpt3\\ss\\lib\\site-packages (from aiohttp->gradio) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in e:\\llm\\chatgpt3\\ss\\lib\\site-packages (from aiohttp->gradio) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\llm\\chatgpt3\\ss\\lib\\site-packages (from aiohttp->gradio) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in e:\\llm\\chatgpt3\\ss\\lib\\site-packages (from aiohttp->gradio) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in e:\\llm\\chatgpt3\\ss\\lib\\site-packages (from aiohttp->gradio) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\llm\\chatgpt3\\ss\\lib\\site-packages (from aiohttp->gradio) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in e:\\llm\\chatgpt3\\ss\\lib\\site-packages (from aiohttp->gradio) (1.3.1)\n",
      "Collecting starlette<0.28.0,>=0.27.0\n",
      "  Using cached starlette-0.27.0-py3-none-any.whl (66 kB)\n",
      "Collecting annotated-types>=0.4.0\n",
      "  Using cached annotated_types-0.5.0-py3-none-any.whl (11 kB)\n",
      "Collecting pydantic-core==2.1.2\n",
      "  Using cached pydantic_core-2.1.2-cp311-none-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: certifi in e:\\llm\\chatgpt3\\ss\\lib\\site-packages (from httpx->gradio) (2023.5.7)\n",
      "Collecting httpcore<0.18.0,>=0.15.0\n",
      "  Using cached httpcore-0.17.3-py3-none-any.whl (74 kB)\n",
      "Requirement already satisfied: idna in e:\\llm\\chatgpt3\\ss\\lib\\site-packages (from httpx->gradio) (3.4)\n",
      "Requirement already satisfied: sniffio in e:\\llm\\chatgpt3\\ss\\lib\\site-packages (from httpx->gradio) (1.3.0)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.1.0-cp311-cp311-win_amd64.whl (470 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.40.0-cp311-cp311-win_amd64.whl (1.9 MB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.4.4-cp311-cp311-win_amd64.whl (55 kB)\n",
      "Collecting pyparsing<3.1,>=2.3.1\n",
      "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\llm\\chatgpt3\\ss\\lib\\site-packages (from requests->gradio) (2.0.3)\n",
      "Requirement already satisfied: colorama in e:\\llm\\chatgpt3\\ss\\lib\\site-packages (from click>=7.0->uvicorn>=0.14.0->gradio) (0.4.6)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in e:\\llm\\chatgpt3\\ss\\lib\\site-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.7.1)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in e:\\llm\\chatgpt3\\ss\\lib\\site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (2023.6.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in e:\\llm\\chatgpt3\\ss\\lib\\site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.29.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in e:\\llm\\chatgpt3\\ss\\lib\\site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.8.10)\n",
      "Collecting uc-micro-py\n",
      "  Using cached uc_micro_py-1.0.2-py3-none-any.whl (6.2 kB)\n",
      "Requirement already satisfied: six>=1.5 in e:\\llm\\chatgpt3\\ss\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->gradio) (1.16.0)\n",
      "Installing collected packages: pytz, pydub, ffmpy, websockets, uc-micro-py, tzdata, typing-extensions, toolz, semantic-version, python-multipart, pyparsing, pillow, orjson, numpy, mdurl, kiwisolver, h11, fsspec, fonttools, filelock, cycler, click, annotated-types, aiofiles, uvicorn, starlette, pydantic-core, pandas, markdown-it-py, linkify-it-py, huggingface-hub, httpcore, contourpy, pydantic, mdit-py-plugins, matplotlib, httpx, gradio-client, fastapi, altair, gradio\n",
      "Successfully installed aiofiles-23.1.0 altair-5.0.1 annotated-types-0.5.0 click-8.1.4 contourpy-1.1.0 cycler-0.11.0 fastapi-0.100.0 ffmpy-0.3.0 filelock-3.12.2 fonttools-4.40.0 fsspec-2023.6.0 gradio-3.36.1 gradio-client-0.2.8 h11-0.14.0 httpcore-0.17.3 httpx-0.24.1 huggingface-hub-0.16.4 kiwisolver-1.4.4 linkify-it-py-2.0.2 markdown-it-py-2.2.0 matplotlib-3.7.2 mdit-py-plugins-0.3.3 mdurl-0.1.2 numpy-1.25.1 orjson-3.9.2 pandas-2.0.3 pillow-10.0.0 pydantic-2.0.2 pydantic-core-2.1.2 pydub-0.25.1 pyparsing-3.0.9 python-multipart-0.0.6 pytz-2023.3 semantic-version-2.10.0 starlette-0.27.0 toolz-0.12.0 typing-extensions-4.7.1 tzdata-2023.3 uc-micro-py-1.0.2 uvicorn-0.22.0 websockets-11.0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4d8857a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9af86444",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_his = [{\"role\":\"system\", \"content\":\"you are an CEO of an Automation and Robotics company in germany\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3950ea70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ChatGpt(inp):\n",
    "    message_his.append({\"role\":\"user\", \"content\":inp})\n",
    "    output = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",messages=message_his)\n",
    "    \n",
    "    reply = output[\"choices\"][0][\"message\"][\"content\"]\n",
    "    message_his.append({\"role\":\"assistant\", \"content\":reply})\n",
    "    return reply\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dac230ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'ðŸ¦œðŸ”— ChatGpt'\n",
    "description = 'das menschen wird zur maschinen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4dcfe706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:8080\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[WinError 225] Operation did not complete successfully because the file contains a virus or potentially unwanted software: 'E:\\\\llm\\\\chatgpt3\\\\ss\\\\Lib\\\\site-packages\\\\gradio\\\\frpc_windows_amd64_v0.2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[1;32mE:\\llm\\chatgpt3\\ss\\Lib\\site-packages\\gradio\\networking.py:190\u001b[0m, in \u001b[0;36msetup_tunnel\u001b[1;34m(local_host, local_port, share_token)\u001b[0m\n\u001b[0;32m    187\u001b[0m tunnel \u001b[38;5;241m=\u001b[39m Tunnel(\n\u001b[0;32m    188\u001b[0m     remote_host, remote_port, local_host, local_port, share_token\n\u001b[0;32m    189\u001b[0m )\n\u001b[1;32m--> 190\u001b[0m address \u001b[38;5;241m=\u001b[39m \u001b[43mtunnel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_tunnel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m address\n",
      "File \u001b[1;32mE:\\llm\\chatgpt3\\ss\\Lib\\site-packages\\gradio\\tunneling.py:59\u001b[0m, in \u001b[0;36mTunnel.start_tunnel\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_binary()\n\u001b[1;32m---> 59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_start_tunnel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBINARY_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\n",
      "File \u001b[1;32mE:\\llm\\chatgpt3\\ss\\Lib\\site-packages\\gradio\\tunneling.py:87\u001b[0m, in \u001b[0;36mTunnel._start_tunnel\u001b[1;34m(self, binary)\u001b[0m\n\u001b[0;32m     70\u001b[0m command \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     71\u001b[0m     binary,\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--disable_log_color\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     86\u001b[0m ]\n\u001b[1;32m---> 87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproc \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPIPE\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m atexit\u001b[38;5;241m.\u001b[39mregister(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkill)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py:1024\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[0;32m   1021\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m   1022\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m-> 1024\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1025\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m   1034\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py:1509\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[0m\n\u001b[0;32m   1508\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1509\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1510\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[0;32m   1511\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1512\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1513\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1514\u001b[0m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1515\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1516\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1518\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1519\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1522\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 225] Operation did not complete successfully because the file contains a virus or potentially unwanted software",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mE:\\llm\\chatgpt3\\ss\\Lib\\site-packages\\gradio\\blocks.py:1927\u001b[0m, in \u001b[0;36mBlocks.launch\u001b[1;34m(self, inline, inbrowser, share, debug, enable_queue, max_threads, auth, auth_message, prevent_thread_lock, show_error, server_name, server_port, show_tips, height, width, encrypt, favicon_path, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_verify, quiet, show_api, file_directories, allowed_paths, blocked_paths, root_path, _frontend, app_kwargs)\u001b[0m\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_url \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_url \u001b[38;5;241m=\u001b[39m \u001b[43mnetworking\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_tunnel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1928\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserver_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserver_port\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshare_token\u001b[49m\n\u001b[0;32m   1929\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1930\u001b[0m \u001b[38;5;28mprint\u001b[39m(strings\u001b[38;5;241m.\u001b[39men[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSHARE_LINK_DISPLAY\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_url))\n",
      "File \u001b[1;32mE:\\llm\\chatgpt3\\ss\\Lib\\site-packages\\gradio\\networking.py:193\u001b[0m, in \u001b[0;36msetup_tunnel\u001b[1;34m(local_host, local_port, share_token)\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 193\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not get share link from Gradio API Server.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [WinError 225] Operation did not complete successfully because the file contains a virus or potentially unwanted software",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[43mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInterface\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatGpt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtitle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m             \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m----> 3\u001b[0m \u001b[43m             \u001b[49m\u001b[43mtheme\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfinlaymacklon/boxy_violet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_port\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8080\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshare\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\llm\\chatgpt3\\ss\\Lib\\site-packages\\gradio\\blocks.py:1938\u001b[0m, in \u001b[0;36mBlocks.launch\u001b[1;34m(self, inline, inbrowser, share, debug, enable_queue, max_threads, auth, auth_message, prevent_thread_lock, show_error, server_name, server_port, show_tips, height, width, encrypt, favicon_path, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_verify, quiet, show_api, file_directories, allowed_paths, blocked_paths, root_path, _frontend, app_kwargs)\u001b[0m\n\u001b[0;32m   1936\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1937\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1938\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBINARY_PATH\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexists\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1939\u001b[0m     \u001b[38;5;28mprint\u001b[39m(strings\u001b[38;5;241m.\u001b[39men[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCOULD_NOT_GET_SHARE_LINK\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   1940\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\pathlib.py:1235\u001b[0m, in \u001b[0;36mPath.exists\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1231\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1232\u001b[0m \u001b[38;5;124;03mWhether this path exists.\u001b[39;00m\n\u001b[0;32m   1233\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1235\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _ignore_error(e):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\pathlib.py:1013\u001b[0m, in \u001b[0;36mPath.stat\u001b[1;34m(self, follow_symlinks)\u001b[0m\n\u001b[0;32m   1008\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstat\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, follow_symlinks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;124;03m    Return the result of the stat() system call on this path, like\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;124;03m    os.stat() does.\u001b[39;00m\n\u001b[0;32m   1012\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1013\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m os\u001b[38;5;241m.\u001b[39mstat(\u001b[38;5;28mself\u001b[39m, follow_symlinks\u001b[38;5;241m=\u001b[39mfollow_symlinks)\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 225] Operation did not complete successfully because the file contains a virus or potentially unwanted software: 'E:\\\\llm\\\\chatgpt3\\\\ss\\\\Lib\\\\site-packages\\\\gradio\\\\frpc_windows_amd64_v0.2'"
     ]
    }
   ],
   "source": [
    "gr.Interface(fn=ChatGpt, inputs=[\"text\"], outputs=[\"text\"], title=title,\n",
    "             description=description,\n",
    "             theme='finlaymacklon/boxy_violet').launch(server_port=8080, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82944b9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ss",
   "language": "python",
   "name": "ss"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
